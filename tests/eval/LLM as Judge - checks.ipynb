{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be005bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c57ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = pd.read_csv(\"../../../sustainable-trs-with-rag/european-city-data/rag-sustainability/results/results-combined_prompts/llm-judge/judged_cities_Claude3Point5Sonnet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763fc3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>response_sustainable</th>\n",
       "      <th>llm_judge_response</th>\n",
       "      <th>llm_judge_response_sustainable</th>\n",
       "      <th>total_rating</th>\n",
       "      <th>total_rating_sustainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_gpt-4o-mini</td>\n",
       "      <td>llama3point1-instruct</td>\n",
       "      <td>Suggest some places to visit during spring. I ...</td>\n",
       "      <td>I recommend Kaunas, Lithuania. I recommend Ka...</td>\n",
       "      <td>I recommend Kaunas, Lithuania because it is a...</td>\n",
       "      <td>Feedback:::\\nTotal rating: 8.5</td>\n",
       "      <td>Feedback:::\\nTotal rating: 9.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_gpt-4o-mini</td>\n",
       "      <td>mistral-instruct</td>\n",
       "      <td>Suggest some places to visit during spring. I ...</td>\n",
       "      <td>1. I recommend Sibiu in Romania.\\n\\nSibiu is a...</td>\n",
       "      <td>1. I recommend Sibiu in Romania.\\n\\nSibiu is a...</td>\n",
       "      <td>Feedback:::\\nTotal rating: 8.5</td>\n",
       "      <td>Feedback:::\\nTotal rating: 8.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_gpt-4o-mini</td>\n",
       "      <td>llama3point1-instruct</td>\n",
       "      <td>I'm planning a trip in July and enjoy beaches,...</td>\n",
       "      <td>I recommend Copenhagen, Denmark because it ha...</td>\n",
       "      <td>I recommend Copenhagen and why you recommende...</td>\n",
       "      <td>Feedback:::\\nTotal rating: 9.0</td>\n",
       "      <td>Feedback:::\\nTotal rating: 8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_gpt-4o-mini</td>\n",
       "      <td>mistral-instruct</td>\n",
       "      <td>I'm planning a trip in July and enjoy beaches,...</td>\n",
       "      <td>1. Option 1: The city of Thessaloniki in Greec...</td>\n",
       "      <td>1. I recommend Varna for your summer holiday i...</td>\n",
       "      <td>Feedback:::\\nTotal rating: 8.5</td>\n",
       "      <td>Feedback:::\\nTotal rating: 7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_gpt-4o-mini</td>\n",
       "      <td>llama3point1-instruct</td>\n",
       "      <td>What are some good destinations for a family v...</td>\n",
       "      <td>I recommend Samsun as the best destination fo...</td>\n",
       "      <td>I recommend Samsun, Turkey because it has a v...</td>\n",
       "      <td>Feedback:::\\nTotal rating: 8.5</td>\n",
       "      <td>Feedback:::\\nTotal rating: 6.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt_id                  model  \\\n",
       "0  0_gpt-4o-mini  llama3point1-instruct   \n",
       "1  0_gpt-4o-mini       mistral-instruct   \n",
       "2  1_gpt-4o-mini  llama3point1-instruct   \n",
       "3  1_gpt-4o-mini       mistral-instruct   \n",
       "4  2_gpt-4o-mini  llama3point1-instruct   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Suggest some places to visit during spring. I ...   \n",
       "1  Suggest some places to visit during spring. I ...   \n",
       "2  I'm planning a trip in July and enjoy beaches,...   \n",
       "3  I'm planning a trip in July and enjoy beaches,...   \n",
       "4  What are some good destinations for a family v...   \n",
       "\n",
       "                                            response  \\\n",
       "0   I recommend Kaunas, Lithuania. I recommend Ka...   \n",
       "1  1. I recommend Sibiu in Romania.\\n\\nSibiu is a...   \n",
       "2   I recommend Copenhagen, Denmark because it ha...   \n",
       "3  1. Option 1: The city of Thessaloniki in Greec...   \n",
       "4   I recommend Samsun as the best destination fo...   \n",
       "\n",
       "                                response_sustainable  \\\n",
       "0   I recommend Kaunas, Lithuania because it is a...   \n",
       "1  1. I recommend Sibiu in Romania.\\n\\nSibiu is a...   \n",
       "2   I recommend Copenhagen and why you recommende...   \n",
       "3  1. I recommend Varna for your summer holiday i...   \n",
       "4   I recommend Samsun, Turkey because it has a v...   \n",
       "\n",
       "               llm_judge_response  llm_judge_response_sustainable  \\\n",
       "0  Feedback:::\\nTotal rating: 8.5  Feedback:::\\nTotal rating: 9.0   \n",
       "1  Feedback:::\\nTotal rating: 8.5  Feedback:::\\nTotal rating: 8.0   \n",
       "2  Feedback:::\\nTotal rating: 9.0  Feedback:::\\nTotal rating: 8.0   \n",
       "3  Feedback:::\\nTotal rating: 8.5  Feedback:::\\nTotal rating: 7.0   \n",
       "4  Feedback:::\\nTotal rating: 8.5  Feedback:::\\nTotal rating: 6.0   \n",
       "\n",
       "   total_rating  total_rating_sustainable  \n",
       "0           8.5                       9.0  \n",
       "1           8.5                       8.0  \n",
       "2           9.0                       8.0  \n",
       "3           8.5                       7.0  \n",
       "4           8.5                       6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = pd.read_csv(\"../../../sustainable-trs-with-rag/european-city-data/rag-sustainability/results/results-combined_prompts/llm-judge/judged_cities_GPT-4.csv\")\n",
    "gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae82de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(df):\n",
    "    llama_results = df.loc[df[\"model\"]==\"llama3point1-instruct\"]\n",
    "    mistral_results = df.loc[df[\"model\"] == \"mistral-instruct\"]\n",
    "    \n",
    "    print(\"\\t llama results mean (Non sustainable)\", llama_results.total_rating.mean())\n",
    "    print(\"\\t llama results mean (Sustainable)\", llama_results.total_rating_sustainable.mean())\n",
    "    \n",
    "    print(\"\\t Mistral results mean (Non sustainable)\", mistral_results.total_rating.mean())\n",
    "    print(\"\\t Mistral results mean (Sustainable)\", mistral_results.total_rating_sustainable.mean())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535e9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sd(df):\n",
    "    llama_results = df.loc[df[\"model\"]==\"llama3point1-instruct\"]\n",
    "    mistral_results = df.loc[df[\"model\"] == \"mistral-instruct\"]\n",
    "    \n",
    "    print(\"\\t llama results mean (Non sustainable)\", llama_results.total_rating.std())\n",
    "    print(\"\\t llama results mean (Sustainable)\", llama_results.total_rating_sustainable.std())\n",
    "    \n",
    "    print(\"\\t Mistral results mean (Non sustainable)\", mistral_results.total_rating.std())\n",
    "    print(\"\\t Mistral results mean (Sustainable)\", mistral_results.total_rating_sustainable.std())\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da6425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean\n",
      "GPT-4 as a judge\n",
      "\t llama results mean (Non sustainable) 8.1625\n",
      "\t llama results mean (Sustainable) 8.11\n",
      "\t Mistral results mean (Non sustainable) 3.8525\n",
      "\t Mistral results mean (Sustainable) 3.78\n",
      "Claude-3.5-sonnet as a judge\n",
      "\t llama results mean (Non sustainable) 6.296482412060302\n",
      "\t llama results mean (Sustainable) 6.3335\n",
      "\t Mistral results mean (Non sustainable) 3.056\n",
      "\t Mistral results mean (Sustainable) 3.0275\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\")\n",
    "print(\"GPT-4 as a judge\")\n",
    "compute_mean(gpt)\n",
    "\n",
    "print(\"Claude-3.5-sonnet as a judge\")\n",
    "compute_mean(claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83344cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD\n",
      "GPT-4 as a judge\n",
      "\t llama results mean (Non sustainable) 1.7806451741379878\n",
      "\t llama results mean (Sustainable) 1.6290083921541174\n",
      "\t Mistral results mean (Non sustainable) 2.7233392431288888\n",
      "\t Mistral results mean (Sustainable) 2.5596599962656\n",
      "Claude-3.5-sonnet as a judge\n",
      "\t llama results mean (Non sustainable) 2.278032486275708\n",
      "\t llama results mean (Sustainable) 2.1422356588597933\n",
      "\t Mistral results mean (Non sustainable) 2.4549332959241856\n",
      "\t Mistral results mean (Sustainable) 2.4847259537676654\n"
     ]
    }
   ],
   "source": [
    "print(\"SD\")\n",
    "print(\"GPT-4 as a judge\")\n",
    "compute_sd(gpt)\n",
    "\n",
    "print(\"Claude-3.5-sonnet as a judge\")\n",
    "compute_sd(claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442f7fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prompt_id',\n",
       " 'model',\n",
       " 'prompt',\n",
       " 'response',\n",
       " 'response_sustainable',\n",
       " 'llm_judge_response',\n",
       " 'llm_judge_response_sustainable',\n",
       " 'total_rating',\n",
       " 'total_rating_sustainable']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637b9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(combined):\n",
    "    llama = combined.loc[combined[\"model\"]==\"llama3point1-instruct\"]\n",
    "    mistral = combined.loc[combined[\"model\"]==\"mistral-instruct\"]\n",
    "    mape_llama = mape(llama.total_rating_gpt4, llama.total_rating_claude)\n",
    "    mape_llama_sustainable = mape(llama.total_rating_sustainable_gpt4, llama.total_rating_sustainable_claude)\n",
    "    \n",
    "    mape_mistral = mape(mistral.total_rating_gpt4, mistral.total_rating_claude)\n",
    "    mape_mistral_sustainable = mape(mistral.total_rating_sustainable_gpt4, mistral.total_rating_sustainable_claude)\n",
    "    \n",
    "    print(\"\\t LLama MAPE (Non Sustainable)\", mape_llama)\n",
    "    print(\"\\t LLama MAPE (Sustainable)\", mape_llama_sustainable)\n",
    "    \n",
    "    print(\"\\n\\t Mistral MAPE (Non Sustainable)\", mape_mistral)\n",
    "    print(\"\\t Mistral MAPE (Sustainable)\", mape_mistral_sustainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e928bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>model</th>\n",
       "      <th>total_rating_gpt4</th>\n",
       "      <th>total_rating_sustainable_gpt4</th>\n",
       "      <th>total_rating_claude</th>\n",
       "      <th>total_rating_sustainable_claude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_gpt-4o-mini</td>\n",
       "      <td>llama3point1-instruct</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_gpt-4o-mini</td>\n",
       "      <td>mistral-instruct</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_gpt-4o-mini</td>\n",
       "      <td>llama3point1-instruct</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_gpt-4o-mini</td>\n",
       "      <td>mistral-instruct</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_gpt-4o-mini</td>\n",
       "      <td>llama3point1-instruct</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>54_gemini-1.5-pro-001</td>\n",
       "      <td>mistral-instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>55_gemini-1.5-pro-001</td>\n",
       "      <td>llama3point1-instruct</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>55_gemini-1.5-pro-001</td>\n",
       "      <td>mistral-instruct</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>56_gemini-1.5-pro-001</td>\n",
       "      <td>llama3point1-instruct</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>56_gemini-1.5-pro-001</td>\n",
       "      <td>mistral-instruct</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 prompt_id                  model  total_rating_gpt4  \\\n",
       "0            0_gpt-4o-mini  llama3point1-instruct                8.5   \n",
       "1            0_gpt-4o-mini       mistral-instruct                8.5   \n",
       "2            1_gpt-4o-mini  llama3point1-instruct                9.0   \n",
       "3            1_gpt-4o-mini       mistral-instruct                8.5   \n",
       "4            2_gpt-4o-mini  llama3point1-instruct                8.5   \n",
       "..                     ...                    ...                ...   \n",
       "395  54_gemini-1.5-pro-001       mistral-instruct                0.0   \n",
       "396  55_gemini-1.5-pro-001  llama3point1-instruct                9.5   \n",
       "397  55_gemini-1.5-pro-001       mistral-instruct                2.0   \n",
       "398  56_gemini-1.5-pro-001  llama3point1-instruct                3.0   \n",
       "399  56_gemini-1.5-pro-001       mistral-instruct                3.0   \n",
       "\n",
       "     total_rating_sustainable_gpt4  total_rating_claude  \\\n",
       "0                              9.0                  7.5   \n",
       "1                              8.0                  5.5   \n",
       "2                              8.0                  6.5   \n",
       "3                              7.0                  6.5   \n",
       "4                              6.0                  5.5   \n",
       "..                             ...                  ...   \n",
       "395                            3.0                  0.0   \n",
       "396                            8.0                  8.5   \n",
       "397                            4.0                  2.0   \n",
       "398                            2.0                  2.5   \n",
       "399                            2.0                  2.5   \n",
       "\n",
       "     total_rating_sustainable_claude  \n",
       "0                                7.5  \n",
       "1                                4.5  \n",
       "2                                3.5  \n",
       "3                                5.5  \n",
       "4                                3.5  \n",
       "..                               ...  \n",
       "395                              3.5  \n",
       "396                              5.5  \n",
       "397                              2.0  \n",
       "398                              1.5  \n",
       "399                              1.5  \n",
       "\n",
       "[400 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"prompt_id\", \"model\", \"total_rating\", \"total_rating_sustainable\"]\n",
    "\n",
    "try:\n",
    "    gpt = gpt[columns]\n",
    "    claude = claude[columns]\n",
    "except KeyError:\n",
    "    gpt = gpt\n",
    "    claude = claude\n",
    "\n",
    "gpt.rename(columns={\"total_rating\": \"total_rating_gpt4\",\"total_rating_sustainable\":\"total_rating_sustainable_gpt4\" }, inplace=True)\n",
    "claude.rename(columns={\"total_rating\": \"total_rating_claude\",\"total_rating_sustainable\":\"total_rating_sustainable_claude\" }, inplace=True)\n",
    "\n",
    "combined = pd.merge(gpt, claude, on=[\"prompt_id\", \"model\"], how=\"left\")\n",
    "combined.fillna(0, inplace=True)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af91469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t LLama MAPE (Non Sustainable) 0.25757350554931824\n",
      "\t LLama MAPE (Sustainable) 0.24001360372084057\n",
      "\n",
      "\t Mistral MAPE (Non Sustainable) 0.3465437958584243\n",
      "\t Mistral MAPE (Sustainable) 0.4222785661835584\n"
     ]
    }
   ],
   "source": [
    "compute_mape(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9729632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".reco-env",
   "language": "python",
   "name": ".reco-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
